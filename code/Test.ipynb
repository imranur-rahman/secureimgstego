{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPV2yKpznQiL3U4EgLLsaHZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"2Lwd8Q87kdcb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1599409476412,"user_tz":-360,"elapsed":25829,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}},"outputId":"cf49a3e6-df30-4d91-cfb3-2d6a384c22f9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"plV5SE6um3mN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599409491520,"user_tz":-360,"elapsed":12880,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}}},"source":["!unzip -q \"/content/drive/My Drive/data/tiny-imagenet-200.zip\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"geSc7LHDi46S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599409500197,"user_tz":-360,"elapsed":3473,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}}},"source":["import numpy as np\n","import cv2\n","\n","import keras\n"," \n","class ImageDataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_files, dim, std, mean, batch_size=64, shuffle=True):\n","        'Initialization'\n","        \n","        self.list_files = list_files\n","        self.dim = dim\n","        self.std = std\n","        self.mean = mean\n","        self.batch_size = batch_size\n","        print(batch_size)\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_files) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        list_files_batch = [self.list_files[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_files_batch)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_files))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def normalize_batch(self, imgs):\n","        imgs = np.array(imgs, dtype=np.float32)\n","        imgs /= 255\n","        return (imgs -  self.mean) / self.std\n","                                                            \n","    def denormalize_batch(self, imgs, should_clip=True):\n","        imgs= imgs * self.std + self.mean \n","        if should_clip:\n","            imgs = np.clip(imgs,0,1)\n","        imgs *= 255\n","        return imgs\n","\n","    def __data_generation(self, list_files_batch):\n","        'Generates data containing batch_size samples' \n","        X = []\n","        for i, fname in enumerate(list_files_batch):\n","            img = cv2.imread(fname)\n","            img = cv2.resize(img, (self.dim[1], self.dim[0]))\n","            # print(img.shape)\n","            X.append(img)\n","        X = self.normalize_batch(X)\n","        mid = int(len(X) / 2)\n","        secret = X[:mid]\n","        cover = X[mid:]\n","        return [secret, cover], [cover, secret]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-LlEsbcjmYl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599409506804,"user_tz":-360,"elapsed":1591,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}}},"source":["import keras\n","import numpy as np\n","import os\n","import pickle\n","\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","import tensorflow as tf\n","from tensorflow.compat.v1.keras.backend import set_session #changed\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, concatenate, Input\n","from keras.layers.noise import GaussianNoise\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import Adadelta, RMSprop\n","\n","\n","\n","def prepare_network(input_shape, input_tensor):\n","    # first block\n","    first_3x3_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","\n","    first_4x4_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","\n","    first_5x5_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","    \n","    first_tensor = concatenate([first_3x3_conv, first_4x4_conv, first_5x5_conv], axis=3)\n","\n","    # second blockGaussianNoise\n","    second_3x3_conv = Conv2D(filters = 50, kernel_size = (3, 3), \n","                            padding = 'Same', activation = 'relu')(first_tensor)\n","\n","    second_4x4_conv = Conv2D(filters = 50, kernel_size = (4, 4), \n","                            padding = 'Same', activation = 'relu')(first_tensor)\n","\n","    second_5x5_conv = Conv2D(filters = 50, kernel_size = (5, 5), \n","                            padding = 'Same', activation = 'relu')(first_tensor)                                                \n","\n","    second_tensor = concatenate([second_3x3_conv, second_4x4_conv, second_5x5_conv], axis=3, name='prepare_net_out')\n","\n","    return second_tensor\n","\n","\n","def hidding_network(input_shape, input_tensor):\n","    # first block\n","    first_3x3_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","\n","    first_4x4_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","\n","    first_5x5_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","    \n","    first_tensor = concatenate([first_3x3_conv, first_4x4_conv, first_5x5_conv], axis=3)\n","\n","    # second block\n","    second_3x3_conv = Conv2D(filters = 50, kernel_size = (3, 3), \n","                            padding = 'Same', activation = 'relu')(first_tensor)\n","\n","    second_4x4_conv = Conv2D(filters = 50, kernel_size = (4, 4), \n","                            padding = 'Same', activation = 'relu')(first_tensor)\n","\n","    second_5x5_conv = Conv2D(filters = 50, kernel_size = (5, 5), \n","                            padding = 'Same', activation = 'relu')(first_tensor)                                                \n","\n","    second_tensor = concatenate([second_3x3_conv, second_4x4_conv, second_5x5_conv], axis=3)\n","\n","    # convert to 3 channels image\n","    out = Conv2D(filters = 3, kernel_size = (1, 1), padding = 'Same', \n","                activation = 'relu', name='hidding_net_out')(second_tensor) \n","                \n","    # add noise\n","    out_noise = GaussianNoise(stddev=0.1, name='hidding_net_out_noise')(out)\n","\n","    return out, out_noise\n","\n","def reveal_network(input_shape, input_tensor):\n","    # first block\n","    first_3x3_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (3, 3),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","\n","    first_4x4_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (4, 4),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","\n","    first_5x5_conv = Sequential([\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu', input_shape = input_shape),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu'),\n","        Conv2D(filters = 50, kernel_size = (5, 5),padding = 'Same', activation = 'relu')\n","    ])(input_tensor)\n","    \n","    first_tensor = concatenate([first_3x3_conv, first_4x4_conv, first_5x5_conv], axis=3)\n","\n","    # second block\n","    second_3x3_conv = Conv2D(filters = 50, kernel_size = (3, 3), \n","                            padding = 'Same', activation = 'relu')(first_tensor)\n","\n","    second_4x4_conv = Conv2D(filters = 50, kernel_size = (4, 4), \n","                            padding = 'Same', activation = 'relu')(first_tensor)\n","\n","    second_5x5_conv = Conv2D(filters = 50, kernel_size = (5, 5), \n","                            padding = 'Same', activation = 'relu')(first_tensor)                                                \n","\n","    second_tensor = concatenate([second_3x3_conv, second_4x4_conv, second_5x5_conv], axis=3)\n","\n","    # convert to 3 channels image\n","    out = Conv2D(filters = 3, kernel_size = (1, 1), padding = 'Same', \n","                activation = 'relu', name = 'reveal_net_out')(second_tensor) \n","    \n","    return out\n","\n","def net(img_shape):\n","    # prepare network\n","    secret_img = Input(shape=img_shape)\n","    prepare_net_input_shape = img_shape\n","    prepare_net_out = prepare_network(prepare_net_input_shape, secret_img)\n","\n","    # hidding network\n","    cover_img = Input(shape=img_shape)\n","    hidding_net_input = concatenate([cover_img, prepare_net_out], axis=3)\n","    hidding_net_input_shape = (*img_shape[:2], 153)\n","    hidding_net_out, hidding_net_out_noise = hidding_network(hidding_net_input_shape, hidding_net_input)\n","\n","    reveal_net_input_shape = img_shape\n","    reveal_net_out = reveal_network(reveal_net_input_shape, hidding_net_out)\n","\n","    model = Model(inputs=[secret_img, cover_img], outputs=[hidding_net_out, reveal_net_out])\n","    return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2tRg9y5Sp7T2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599409515622,"user_tz":-360,"elapsed":1077,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}},"outputId":"02c60e13-4b13-4d67-c3e7-5da9179fdbc8"},"source":["!rm -r temp"],"execution_count":5,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'temp': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9aClBGeMpoas","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599409518567,"user_tz":-360,"elapsed":1094,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}}},"source":["!mkdir temp"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAfWC9zmjJH6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1599409542674,"user_tz":-360,"elapsed":20654,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}},"outputId":"c7cf6c9e-f683-4baa-cec0-cf0b83100f11"},"source":["import numpy as np\n","import os\n","import cv2\n","import pickle\n","import glob\n","import random\n","import pandas as pd\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","import tensorflow as tf\n","import keras\n","from keras import backend as K\n","from tensorflow.compat.v1.keras.backend import set_session\n","from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n","from keras.optimizers import Adadelta, RMSprop\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from keras.utils import multi_gpu_model\n","\n","#from model import *\n","#from dataset import ImageDataGenerator \n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","set_session(tf.compat.v1.Session(config=config))\n","\n","\n","def read_image(fname, size):\n","    img = cv2.imread(fname)\n","    img = cv2.resize(img, size)\n","    return img\n","list_files = []\n","list_file_pattern = [\"tiny-imagenet-200/train/*/*/*.JPEG\"]\n","for file_pattern in list_file_pattern:\n","     sub_list_files = glob.glob(file_pattern)\n","     list_files = [*list_files, *sub_list_files]\n","#changed\n","'''\n","def get_file():\n","    data = pd.read_csv('shape.csv')\n","    fname, x, y = data.iloc[:, 0], data.iloc[:, 1], data.iloc[:, 2]\n","    list_files = []\n","    for i in range(len(fname)):\n","        rate = y[i] / x[i]\n","        if 1.0 < rate and rate < 1.4:\n","            list_files.append(fname[i])\n","    return list_files\n","\n","#list_files = get_file()\n","'''\n","random.seed(10)\n","random.shuffle(list_files)\n","#list_files = list_files[:5000]\n","\n","N_TEST_SAMPLES = int(0.1 * len(list_files))\n","N_TRAIN_SAMPLES= len(list_files) - N_TEST_SAMPLES\n","list_files_train, list_files_val = list_files[:N_TRAIN_SAMPLES], list_files[N_TRAIN_SAMPLES:]\n","\n","print(\"Total number of image:\", len(list_files))\n","print(\"Total number of training:\", N_TRAIN_SAMPLES)\n","print(\"Total number of testing:\", N_TEST_SAMPLES)\n","\n","BATCH_SIZE = 16\n","params = {\n","    'dim': (64, 64, 3),\n","    'std': np.array([0.229, 0.224, 0.225]),\n","    'mean': np.array([0.485, 0.456, 0.406]),\n","    'batch_size': BATCH_SIZE\n","}\n","\n","# Generators\n","testing_generator = ImageDataGenerator(list_files_val[:64], **params, shuffle=False)\n","\n","\n","# Restore model\n","'''\n","with tf.device(\"/cpu:0\"):\n","    model = net(params['dim'])\n","model = multi_gpu_model(model, gpus=2)\n","'''\n","model = net(params['dim']) #changed\n","model.load_weights(\"/content/drive/My Drive/Model/weights-90-1.98.hdf5\")#changed\n","print(\"Done loaded model!\")\n","\n","\n","pair_prediction = model.predict_generator(testing_generator, verbose=1) #changed\n","cover_pred = testing_generator.denormalize_batch(pair_prediction[0])\n","secret_pred = testing_generator.denormalize_batch(pair_prediction[1])\n","print(len(cover_pred))\n","\n","\n","def mse(imageA, imageB):\n","\t# the 'Mean Squared Error' between the two images is the\n","\t# sum of the squared difference between the two images;\n","\t# NOTE: the two images must have the same dimension\n","\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n","\terr /= float(imageA.shape[0] * imageA.shape[1])\n","\t\n","\t# return the MSE, the lower the error, the more \"similar\"\n","\t# the two images are\n","\treturn err\n","\n","secret_mse = 0\n","cover_mse = 0\n","\n","path_name  =\"/content/temp/\"\n","\n","for i in range(0,8):\n","    idx_secret = i\n","    idx_cover = idx_secret + 8\n","    secret = read_image(list_files_val[idx_secret], (params['dim'][1], params['dim'][0]))\n","    cover = read_image(list_files_val[idx_cover], (params['dim'][1], params['dim'][0]))\n","    # concat all images and save\n","    concat_all = np.concatenate([secret, cover, cover_pred[i], secret_pred[i]], axis=1)\n","    cv2.imwrite( path_name+str(i) + '.jpg', concat_all) #changed\n","    cv2.imwrite( path_name+'s_'+ str(i) + '.jpg', secret) #changed\n","    cv2.imwrite( path_name+'c_'+ str(i) + '.jpg', cover)\n","    cv2.imwrite( path_name+'cp_'+ str(i) + '.jpg', cover_pred[i])\n","    cv2.imwrite( path_name+'sp_'+ str(i) + '.jpg', secret_pred[i])\n","    secret_mse = secret_mse + mse(secret, secret_pred[i])\n","    cover_mse = cover_mse + mse(cover, cover_pred[i])\n","'''\n","for i in range(len(cover_pred)):\n","    idx_secret = int(i / BATCH_SIZE) * 2 * BATCH_SIZE + i % BATCH_SIZE\n","    idx_cover = idx_secret + BATCH_SIZE\n","    secret = read_image(list_files_val[idx_secret], (params['dim'][1], params['dim'][0]))\n","    cover = read_image(list_files_val[idx_cover], (params['dim'][1], params['dim'][0]))\n","    # concat all images and save\n","    concat_all = np.concatenate([secret, cover, cover_pred[i], secret_pred[i]], axis=1)\n","    cv2.imwrite( path_name+str(i) + '.jpg', concat_all) #changed\n","    cv2.imwrite( path_name+'s_'+ str(i) + '.jpg', secret) #changed\n","    cv2.imwrite( path_name+'c_'+ str(i) + '.jpg', cover)\n","    cv2.imwrite( path_name+'cp_'+ str(i) + '.jpg', cover_pred[i])\n","    cv2.imwrite( path_name+'sp_'+ str(i) + '.jpg', secret_pred[i])\n","    secret_mse = secret_mse + mse(secret, secret_pred[i])\n","    cover_mse = cover_mse + mse(cover, cover_pred[i])\n","\n","secret_mse = secret_mse / len(cover_pred)\n","cover_mse = cover_mse / len(cover_pred)\n","'''\n","\n","print(\"Secret_mse : \",secret_mse)\n","print(\"Cover_mse : \",cover_mse)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Total number of image: 100000\n","Total number of training: 90000\n","Total number of testing: 10000\n","16\n","Done loaded model!\n","WARNING:tensorflow:From <ipython-input-7-cb7fc4bae741>:88: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.predict, which supports generators.\n","4/4 [==============================] - 13s 3s/step\n","32\n","Secret_mse :  115294.47927060546\n","Cover_mse :  58665.674558540624\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tEHBVLlGkNaG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599393698868,"user_tz":-360,"elapsed":1089,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}},"outputId":"aec20118-1951-49d9-85eb-062ee32bc9bd"},"source":["import numpy as np\n","def mse(imageA, imageB):\n","\t# the 'Mean Squared Error' between the two images is the\n","\t# sum of the squared difference between the two images;\n","\t# NOTE: the two images must have the same dimension\n","\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n","\terr /= float(imageA.shape[0] * imageA.shape[1])\n","\t\n","\t# return the MSE, the lower the error, the more \"similar\"\n","\t# the two images are\n","\treturn err\n","\t\n","imageA = np.random.rand(64,64,3)\n","imageB = np.random.rand(64,64,3)\n","print(mse(imageA,imageB))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.501400107120468\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ki1CVegHTKGY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1599395394083,"user_tz":-360,"elapsed":1576,"user":{"displayName":"Deep Steganography","photoUrl":"","userId":"17444086891419800955"}},"outputId":"b173c441-5d6d-4489-e95e-bfb2979d2ba5"},"source":["imageA = np.random.rand(3,64,64)\n","imageB = np.random.rand(3,64,64)\n","model = net(params['dim']) #changed\n","model.load_weights(\"/content/drive/My Drive/Model/weights-90-1.98.hdf5\")#changed\n","model.predict([imageA,imageB],batch_size=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input Tensor(\"input_29:0\", shape=(None, 64, 64, 3), dtype=float32), but it was called on an input with incompatible shape (1, 64, 64).\n","WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input Tensor(\"input_30:0\", shape=(None, 64, 64, 3), dtype=float32), but it was called on an input with incompatible shape (1, 64, 64).\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-907159c4e746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Model/weights-90-1.98.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimageA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:196 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_126 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [1, 64, 64]\n"]}]}]}