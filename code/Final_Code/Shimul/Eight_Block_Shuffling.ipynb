{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Eight_Block_Shuffling.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXZDAo5KrUin","executionInfo":{"status":"ok","timestamp":1619762082650,"user_tz":-360,"elapsed":21943,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}},"outputId":"f95a508d-3376-47bb-c12e-2ea038bf78d4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jQJz-jm0dmGI","executionInfo":{"status":"ok","timestamp":1619762096853,"user_tz":-360,"elapsed":36131,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["!unzip -q \"/content/drive/My Drive/data/tiny-imagenet-200.zip\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qq7DxdSdd30A","executionInfo":{"status":"ok","timestamp":1619762098874,"user_tz":-360,"elapsed":38143,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["### Imports ###\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n","from keras.engine.topology import Network\n","from keras.layers import *\n","from keras.models import Model\n","from keras.preprocessing import image\n","import keras.backend as K\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import random\n","import scipy.misc\n","from tqdm import *\n","\n","%matplotlib inline"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KBzMgfUDuGC","executionInfo":{"status":"ok","timestamp":1619762098875,"user_tz":-360,"elapsed":38135,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["os.environ['PYTHONHASHSEED'] = '0'\n","np.random.seed(123)\n","random.seed(121)\n","tf.random.set_seed(85)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3LvmkAvd-g1","executionInfo":{"status":"ok","timestamp":1619762098876,"user_tz":-360,"elapsed":38125,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["### Constants ###\n","DATA_DIR = \"/content/tiny-imagenet-200\"\n","TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n","TEST_DIR = os.path.join(DATA_DIR, \"test\")\n","\n","IMG_SHAPE = (64, 64)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFuoYaX_eEfd","executionInfo":{"status":"ok","timestamp":1619762098877,"user_tz":-360,"elapsed":38111,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["def load_dataset_small(num_images_per_class_train=100, num_images_test=1000):\n","    \"\"\"Loads training and test datasets, from Tiny ImageNet Visual Recogition Challenge.\n","\n","    Arguments:\n","        num_images_per_class_train: number of images per class to load into training dataset.\n","        num_images_test: total number of images to load into training dataset.\n","    \"\"\"\n","    X_train = []\n","    X_test = []\n","    \n","    # Create training set.\n","    for c in os.listdir(TRAIN_DIR):\n","        c_dir = os.path.join(TRAIN_DIR, c, 'images')\n","        c_imgs = os.listdir(c_dir)\n","        random.shuffle(c_imgs)\n","        #for img_name_i in c_imgs[0:num_images_per_class_train]:\n","        for img_name_i in c_imgs:\n","            img_i = image.load_img(os.path.join(c_dir, img_name_i))\n","            x = image.img_to_array(img_i)\n","            X_train.append(x)\n","    random.shuffle(X_train)\n","    \n","    # Create test set.\n","    test_dir = os.path.join(TEST_DIR, 'images')\n","    test_imgs = os.listdir(test_dir)\n","    random.shuffle(test_imgs)\n","    #for img_name_i in test_imgs[0:num_images_test]:\n","    for img_name_i in test_imgs:\n","        img_i = image.load_img(os.path.join(test_dir, img_name_i))\n","        x = image.img_to_array(img_i)\n","        X_test.append(x)\n","\n","    # Return train and test data as numpy arrays.\n","    return np.array(X_train), np.array(X_test)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9paKdd2egMy","executionInfo":{"status":"ok","timestamp":1619762153759,"user_tz":-360,"elapsed":92983,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}},"outputId":"a94ebdf2-f6a7-4a44-c0b9-2aef92dfb992"},"source":["# Load dataset.\n","X_train_orig, X_test_orig = load_dataset_small()\n","\n","# Normalize image vectors.\n","X_train = X_train_orig/255.\n","X_test = X_test_orig/255.\n","\n","# Print statistics.\n","print (\"Number of training examples = \" + str(X_train.shape[0]))\n","print (\"Number of test examples = \" + str(X_test.shape[0]))\n","print (\"X_train shape: \" + str(X_train.shape)) # Should be (train_size, 64, 64, 3)."],"execution_count":7,"outputs":[{"output_type":"stream","text":["Number of training examples = 100000\n","Number of test examples = 10000\n","X_train shape: (100000, 64, 64, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XgeDQ4FEcZVy","executionInfo":{"status":"ok","timestamp":1619762153760,"user_tz":-360,"elapsed":92975,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["del X_train_orig, X_test_orig"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"2c9c1V9keQIa","executionInfo":{"status":"ok","timestamp":1619762153760,"user_tz":-360,"elapsed":92966,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["# We split training set into two halfs.\n","# First half is used for training as secret images, second half for cover images.\n","\n","# S: secret image\n","input_S = X_train[0:X_train.shape[0] // 2]\n","\n","# C: cover image\n","input_C = X_train[X_train.shape[0] // 2:]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLU7qOLzfY8u","executionInfo":{"status":"ok","timestamp":1619762153761,"user_tz":-360,"elapsed":92959,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["def lr_schedule(epoch_idx):\n","    if epoch_idx < 200:\n","        return 0.001\n","    elif epoch_idx < 400:\n","        return 0.0003\n","    elif epoch_idx < 600:\n","        return 0.0001\n","    else:\n","        return 0.00003"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHxbbK4IJ-iC","executionInfo":{"status":"ok","timestamp":1619762153762,"user_tz":-360,"elapsed":92953,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["# Block size to fragment the image\n","block_size = 8"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"goEnMtu5Bik3"},"source":["### Model Implementation (Shuffling)"]},{"cell_type":"code","metadata":{"id":"O7wa0a5TcxhS","executionInfo":{"status":"ok","timestamp":1619762213686,"user_tz":-360,"elapsed":1867,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["# Variable used to weight the losses of the secret and cover images (See paper for more details)\n","beta = 1.0\n","    \n","# Loss for reveal network\n","def rev_loss(y_true, y_pred):\n","    # Loss for reveal network is: beta * |S-S'|\n","    return beta * K.sum(K.square(y_true - y_pred))\n","\n","# Loss for the full model, used for preparation and hidding networks\n","def full_loss(y_true, y_pred):\n","    # Loss for the full model is: |C-C'| + beta * |S-S'|\n","    s_true, c_true = y_true[:,:,:,0:3], y_true[:,:,:,3:6]\n","    s_pred, c_pred = y_pred[:,:,:,0:3], y_pred[:,:,:,3:6]\n","    s_loss = K.sum(K.square(s_true - s_pred))\n","    c_loss = K.sum(K.square(c_true - c_pred))\n","    return s_loss + c_loss\n","\n","\n","# Returns the encoder as a Keras model, composed by Preparation and Hiding Networks.\n","def make_encoder(input_size):\n","    # Calculations for dividing into blocks\n","    block_in_one_axis = input_size[1] // block_size\n","    total_block = block_in_one_axis**2\n","\n","    batch_size = 32\n","    channel = input_size[2]\n","\n","    input_S = Input(shape=(input_size))\n","    input_C= Input(shape=(input_size))\n","    input_K = Input(shape=(block_size,))\n","\n","    blocks = tf.image.extract_patches(input_S,sizes=[1,block_size,block_size,1],strides=[1,block_size,block_size,1],rates=[1, 1, 1, 1],padding='VALID')\n","    blocks = tf.reshape(blocks,[total_block, block_size, block_size, channel])\n","\n","    integer_K = tf.dtypes.cast(input_K, tf.int32)\n","\n","    i1 = tf.expand_dims(tf.range(tf.shape(integer_K)[0]), axis = 1)\n","    i1 = tf.tile(i1, [1, total_block])\n","    indices = tf.stack([i1,input_K ], axis=-1)\n","\n","    scattered = tf.scatter_nd(indices, blocks, blocks.shape)\n","\n","    scattered_blocks = tf.unstack(scattered, axis =1)\n","    scattered_tensor_row_wise = [tf.keras.layers.concatenate(scattered_blocks[x:x+block_in_one_axis], axis = -2) for x in tf.range(0,total_block,block_in_one_axis)]\n","    x = tf.keras.layers.concatenate(scattered_tensor_row_wise, axis = 1)\n","\n","\n","    # Preparation Network\n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_3x3')(x) #changed\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_4x4')(x) #changed\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_5x5')(x) #changed\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x = concatenate([input_C, x])\n","    \n","    # Hiding network\n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid5_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    output_Cprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_C')(x)\n","    \n","    return Model(inputs=[input_S, input_C, input_K], #changed\n","                 outputs=output_Cprime,\n","                 name = 'Encoder')\n","\n","# Returns the decoder as a Keras model, composed by the Reveal Network\n","def make_decoder(input_size, fixed=False):\n","    # Calculations for dividing into blocks\n","    block_in_one_axis = input_size[1] // block_size\n","    total_block = block_in_one_axis**2\n","\n","    batch_size = 32\n","    channel = input_size[2]\n","    \n","    # Reveal network\n","    reveal_input = Input(shape=(input_size))\n","    input_K = Input(shape=(total_block,))\n","\n","    # Adding Gaussian noise with 0.01 standard deviation.\n","    input_with_noise = GaussianNoise(0.01, name='output_C_noise')(reveal_input) #changed\n","    x = input_with_noise\n","\n","    #x = concatenate([input_with_noise, input_K])\n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_3x3')(x) #changed\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev5_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_S')(x)\n","\n","\n","\n","    blocks = tf.image.extract_patches(x,sizes=[1,block_size,block_size,1],strides=[1,block_size,block_size,1],rates=[1, 1, 1, 1],padding='VALID')\n","    blocks = tf.reshape(blocks,[total_block, block_size, block_size, channel])\n","\n","    integer_K = tf.dtypes.cast(input_K, tf.int32)\n","\n","    i1 = tf.expand_dims(tf.range(tf.shape(integer_K)[0]), axis = 1)\n","    i1 = tf.tile(i1, [1, total_block])\n","    indices = tf.stack([i1,input_K ], axis=-1)\n","\n","    scattered = tf.scatter_nd(indices, blocks, blocks.shape)\n","\n","    scattered_blocks = tf.unstack(scattered, axis =1)\n","    scattered_tensor_row_wise = [tf.keras.layers.concatenate(scattered_blocks[x:x+block_in_one_axis], axis = -2) for x in tf.range(0,total_block,block_in_one_axis)]\n","    output_Sprime = tf.keras.layers.concatenate(scattered_tensor_row_wise, axis = 1)\n","\n","    \n","    if not fixed:\n","        return Model(inputs=[reveal_input,input_K],\n","                     outputs=output_Sprime,\n","                     name = 'Decoder')\n","    # else:\n","    #     return Container(inputs=reveal_input,\n","    #                      outputs=output_Sprime,\n","    #                      name = 'DecoderFixed')                    # Changed\n","    else:\n","      return Network(inputs=[reveal_input,input_K],   #changed\n","                      outputs=output_Sprime,\n","                      name = 'DecoderFixed')\n","\n","# Full model.\n","def make_model(input_size):\n","    # Calculations for dividing into blocks\n","    block_in_one_axis = input_size[1] // block_size\n","    total_block = block_in_one_axis**2\n","\n","    input_S = Input(shape=(input_size))\n","    input_C= Input(shape=(input_size)) \n","    input_K = Input(shape=(total_block,))\n","    \n","    encoder = make_encoder(input_size)\n","    \n","    decoder = make_decoder(input_size)\n","    decoder.compile(optimizer='adam', loss=rev_loss)\n","    decoder.trainable = False\n","    \n","    output_Cprime = encoder([input_S, input_C, input_K]) #changed\n","    output_Sprime = decoder([output_Cprime, input_K]) #changed\n","\n","    autoencoder = Model(inputs=[input_S, input_C, input_K],\n","                        outputs=concatenate([output_Sprime, output_Cprime]))\n","    autoencoder.compile(optimizer='adam', loss=full_loss)\n","    return encoder, decoder, autoencoder"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jVDE5sSkXly7"},"source":["### 1st 10 Epoch :"]},{"cell_type":"code","metadata":{"id":"_BaJyO52fu4W","executionInfo":{"status":"ok","timestamp":1619762216409,"user_tz":-360,"elapsed":1412,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}}},"source":["def Train(e) :\n","  NB_EPOCHS = e\n","  BATCH_SIZE = 32\n","  m = input_S.shape[0]\n","  ae_loss_history = []\n","  rev_loss_history = []\n","  encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])\n","\n","  # Calculations for dividing into blocks\n","  block_in_one_axis = input_S.shape[1] // block_size\n","  total_block = block_in_one_axis**2\n","  \n","  for epoch in range(NB_EPOCHS):\n","      np.random.shuffle(input_S)\n","      np.random.shuffle(input_C)\n","      \n","      t = tqdm(range(0, input_S.shape[0], BATCH_SIZE),mininterval=0)\n","      ae_loss = []\n","      rev_loss = []\n","      for idx in t:\n","          \n","          batch_S = input_S[idx:min(idx + BATCH_SIZE, m)]\n","          batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n","          batch_K = np.zeros(shape=(len(batch_S), total_block))\n","          for i in range(len(batch_S)):\n","            batch_K[i] = random.sample(range(0, total_block), total_block)\n","          \n","          C_prime = encoder_model.predict([batch_S, batch_C, batch_K])\n","          \n","          ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S, batch_C, batch_K], y=np.concatenate((batch_S, batch_C),axis=3)))\n","          rev_loss.append(reveal_model.train_on_batch(x=[C_prime,batch_K],y=batch_S))\n","          \n","          # Update learning rate\n","          K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n","          K.set_value(reveal_model.optimizer.lr, lr_schedule(epoch))\n","          \n","          t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss)))\n","      ae_loss_history.append(np.mean(ae_loss))\n","      rev_loss_history.append(np.mean(rev_loss))\n","  return ae_loss_history, rev_loss_history, encoder_model, reveal_model, autoencoder_model "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvVzSUZBxIZT","colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"status":"error","timestamp":1619762224922,"user_tz":-360,"elapsed":7163,"user":{"displayName":"Imranur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKJaww3Ye-syh_Q4HRRNfpOmxbhRDcHlZ_7w6Q=s64","userId":"05802204788746646338"}},"outputId":"cdb4aea3-e62a-49c3-d348-0098d766068a"},"source":["ae_loss_history, rev_loss_history, encoder_model, reveal_model, autoencoder_model = Train(10)\n","autoencoder_model.save_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_model_100k_10e.hdf5')\n","encoder_model.save_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_encoder_model_100k_10e.hdf5')\n","reveal_model.save_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_model_100k_10e.hdf5')\n","\n","with open('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_100k_10e.txt', 'w') as f:\n","    for item in ae_loss_history:\n","        f.write(\"%s,\" % item)\n","with open('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_100k_10e.txt', 'w') as f:\n","    for item in rev_loss_history:\n","        f.write(\"%s,\" % item)\n","\n","plt.plot(ae_loss_history)\n","plt.title('Model loss')\n","plt.ylabel('ae_Loss')\n","plt.xlabel('1st 10 Epoch')\n","plt.show()\n","plt.plot(rev_loss_history)\n","plt.title('Model loss')\n","plt.ylabel('rev_Loss')\n","plt.xlabel('1st 10 Epoch')\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m   \u001b[0mvalue_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvalue_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError(\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;34m'Cannot convert a symbolic Keras input/output to a numpy array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;34m'This error may indicate that you\\'re trying to pass a symbolic value '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    437\u001b[0m               \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m               as_ref=input_arg.is_ref)\n\u001b[0m\u001b[1;32m    439\u001b[0m           if input_arg.number_attr and len(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor\u001b[0;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m             ctx=ctx))\n\u001b[0m\u001b[1;32m   1609\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1508\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[1;32m   1510\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor 'Placeholder_1:0' shape=(None, 8) dtype=float32>","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-a14dc944e658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mae_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreveal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mautoencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_model_100k_10e.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_encoder_model_100k_10e.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreveal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_model_100k_10e.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-8496f3155531>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mae_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mrev_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreveal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_S\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Calculations for dividing into blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-19adb4754bfe>\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(input_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0minput_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-19adb4754bfe>\u001b[0m in \u001b[0;36mmake_encoder\u001b[0;34m(input_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_K\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mscattered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(op, args, kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GLOBAL_DISPATCHERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         for x in nest.flatten([args, kwargs])):\n\u001b[0;32m-> 1450\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mTFOpLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1451\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1410\u001b[0m                        (axis, -expanded_num_dims, expanded_num_dims))\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6396\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6397\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 6398\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   6399\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6400\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    464\u001b[0m                               (prefix, dtype.name))\n\u001b[1;32m    465\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s that don't all match.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             raise TypeError(\n","\u001b[0;31mTypeError\u001b[0m: Tensors in list passed to 'values' of 'Pack' Op have types [int32, float32] that don't all match."]}]},{"cell_type":"markdown","metadata":{"id":"asd4Y8OJXRS2"},"source":["### 2nd 10 epochs"]},{"cell_type":"code","metadata":{"id":"3lJ6cHoQFyqw"},"source":["def Train(e) :\n","  NB_EPOCHS = e\n","  BATCH_SIZE = 32\n","  m = input_S.shape[0]\n","  ae_loss_history = []\n","  rev_loss_history = []\n","  encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])\n","  autoencoder_model.load_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_model_100k_10e.hdf5')\n","  encoder_model.load_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_encoder_model_100k_10e.hdf5')\n","  reveal_model.load_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_model_100k_10e.hdf5')\n","  \n","  # Calculations for dividing into blocks\n","  block_in_one_axis = input_S.shape[1] // block_size\n","  total_block = block_in_one_axis**2\n","\n","  for epoch in range(NB_EPOCHS):\n","      np.random.shuffle(input_S)\n","      np.random.shuffle(input_C)\n","      \n","      t = tqdm(range(0, input_S.shape[0], BATCH_SIZE),mininterval=0)\n","      ae_loss = []\n","      rev_loss = []\n","      for idx in t:\n","          \n","          batch_S = input_S[idx:min(idx + BATCH_SIZE, m)]\n","          batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n","          batch_K = np.zeros(shape=(len(batch_S), total_block))\n","          for i in range(len(batch_S)):\n","            batch_K[i] = random.sample(range(0, total_block), total_block)\n","          \n","          C_prime = encoder_model.predict([batch_S, batch_C, batch_K])\n","          \n","          ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S, batch_C, batch_K], y=np.concatenate((batch_S, batch_C),axis=3)))\n","          rev_loss.append(reveal_model.train_on_batch(x=[C_prime,batch_K],y=batch_S))\n","          \n","          # Update learning rate\n","          K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n","          K.set_value(reveal_model.optimizer.lr, lr_schedule(epoch))\n","          \n","          t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss)))\n","      ae_loss_history.append(np.mean(ae_loss))\n","      rev_loss_history.append(np.mean(rev_loss))\n","  return ae_loss_history, rev_loss_history, encoder_model, reveal_model, autoencoder_model "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQDGWe2Hxn7D"},"source":["ae_loss_history, rev_loss_history, encoder_model, reveal_model, autoencoder_model = Train(10)\n","\n","autoencoder_model.save_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_model_100k_20e.hdf5')\n","encoder_model.save_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_encoder_model_100k_20e.hdf5')\n","reveal_model.save_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_model_100k_20e.hdf5')\n","\n","with open('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_100k_20e.txt', 'w') as f:\n","    for item in ae_loss_history:\n","        f.write(\"%s,\" % item)\n","with open('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_100k_20e.txt', 'w') as f:\n","    for item in rev_loss_history:\n","        f.write(\"%s,\" % item)\n","\n","plt.plot(ae_loss_history)\n","plt.title('Model loss')\n","plt.ylabel('ae_Loss')\n","plt.xlabel('2nd 10 Epoch')\n","plt.show()\n","plt.plot(rev_loss_history)\n","plt.title('Model loss')\n","plt.ylabel('rev_Loss')\n","plt.xlabel('2nd 10 Epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yNGfuPmox-B7"},"source":["### Test "]},{"cell_type":"code","metadata":{"id":"vcBdN64kyGdc"},"source":["# S: secret image\n","input_S = X_test[0:X_test.shape[0] // 2]\n","\n","# C: cover image\n","input_C = X_test[X_test.shape[0] // 2:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpxLIyRkGdQk"},"source":["# Calculations for dividing into blocks\n","input_size = input_S.shape[1]\n","block_in_one_axis = input_size // block_size\n","total_block = block_in_one_axis**2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrc8x8wn0DL5"},"source":["input_K = np.zeros(shape=(len(input_S), total_block))\n","for i in range(len(input_S)):\n","    input_K[i] = random.sample(range(0, total_block), total_block)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5s8laUJHz4QS"},"source":["encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])\n","autoencoder_model.load_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_autoencoder_model_100k_50e.hdf5')\n","encoder_model.load_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_encoder_model_100k_50e.hdf5')\n","reveal_model.load_weights('/content/drive/My Drive/Final_Model/eight_block_shuffling/eight_block_shuffling_reveal_model_100k_50e.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTx-Xy1R081w"},"source":["def pixel_errors(input_S, input_C, decoded_S, decoded_C):\n","    \"\"\"Calculates mean of Sum of Squared Errors per pixel for cover and secret images. \"\"\"\n","    rmse_Spixel = np.sqrt(np.mean(np.square(255*(input_S - decoded_S))))\n","    rmse_Cpixel = np.sqrt(np.mean(np.square(255*(input_C - decoded_C))))\n","    \n","    return rmse_Spixel, rmse_Cpixel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttAtZ7pUznjU"},"source":["decoded = autoencoder_model.predict([input_S, input_C, input_K])\n","decoded_S, decoded_C = decoded[...,0:3], decoded[...,3:6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lirXe7rD0n7r"},"source":["S_error, C_error = pixel_errors(input_S, input_C, decoded_S, decoded_C)\n","\n","print (\"S error per pixel [0, 255]:\", S_error)\n","print (\"C error per pixel [0, 255]:\", C_error)"],"execution_count":null,"outputs":[]}]}