{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Baluja.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCpJ8/AcofeT9DCB9cVCH0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"c3t8CRA88ToX"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYnwuKQKeVMi"},"source":["!unzip -q \"/content/drive/My Drive/data/tiny-imagenet-200.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-ix7aBOeYri"},"source":["### Imports ###\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n","from keras.engine.topology import Network\n","from keras.layers import *\n","from keras.models import Model\n","from keras.preprocessing import image\n","import keras.backend as K\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import random\n","import scipy.misc\n","from tqdm import *\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8Bbm0Q1ebJC"},"source":["### Constants ###\n","DATA_DIR = \"/content/tiny-imagenet-200\"\n","TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n","TEST_DIR = os.path.join(DATA_DIR, \"test\")\n","\n","IMG_SHAPE = (64, 64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QvAnyYPefqO"},"source":["def load_dataset_small(num_images_per_class_train=100, num_images_test=1000):\n","    \"\"\"Loads training and test datasets, from Tiny ImageNet Visual Recogition Challenge.\n","\n","    Arguments:\n","        num_images_per_class_train: number of images per class to load into training dataset.\n","        num_images_test: total number of images to load into training dataset.\n","    \"\"\"\n","    X_train = []\n","    X_test = []\n","    \n","    # Create training set.\n","    for c in os.listdir(TRAIN_DIR):\n","        c_dir = os.path.join(TRAIN_DIR, c, 'images')\n","        c_imgs = os.listdir(c_dir)\n","        random.shuffle(c_imgs)\n","        #for img_name_i in c_imgs[0:num_images_per_class_train]:\n","        for img_name_i in c_imgs:\n","            img_i = image.load_img(os.path.join(c_dir, img_name_i))\n","            x = image.img_to_array(img_i)\n","            X_train.append(x)\n","    random.shuffle(X_train)\n","    \n","    # Create test set.\n","    test_dir = os.path.join(TEST_DIR, 'images')\n","    test_imgs = os.listdir(test_dir)\n","    random.shuffle(test_imgs)\n","    #for img_name_i in test_imgs[0:num_images_test]:\n","    for img_name_i in test_imgs:\n","        img_i = image.load_img(os.path.join(test_dir, img_name_i))\n","        x = image.img_to_array(img_i)\n","        X_test.append(x)\n","\n","    # Return train and test data as numpy arrays.\n","    return np.array(X_train), np.array(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KO2H3AREei-h"},"source":["# Load dataset.\n","X_train_orig, X_test_orig = load_dataset_small()\n","\n","# Normalize image vectors.\n","X_train = X_train_orig/255.\n","X_test = X_test_orig/255.\n","\n","# Print statistics.\n","print (\"Number of training examples = \" + str(X_train.shape[0]))\n","print (\"Number of test examples = \" + str(X_test.shape[0]))\n","print (\"X_train shape: \" + str(X_train.shape)) # Should be (train_size, 64, 64, 3)."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiOgczeremSm"},"source":["del X_train_orig, X_test_orig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMPeGYDteo9e"},"source":["# We split training set into two halfs.\n","# First half is used for training as secret images, second half for cover images.\n","\n","# S: secret image\n","input_S = X_train[0:X_train.shape[0] // 2]\n","\n","# C: cover image\n","input_C = X_train[X_train.shape[0] // 2:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LT_hCojPerK3"},"source":["def lr_schedule(epoch_idx):\n","    if epoch_idx < 200:\n","        return 0.001\n","    elif epoch_idx < 400:\n","        return 0.0003\n","    elif epoch_idx < 600:\n","        return 0.0001\n","    else:\n","        return 0.00003"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dyfdF-ietQ3"},"source":["# Variable used to weight the losses of the secret and cover images (See paper for more details)\n","beta = 1.0\n","    \n","# Loss for reveal network\n","def rev_loss(y_true, y_pred):\n","    # Loss for reveal network is: beta * |S-S'|\n","    return beta * K.sum(K.square(y_true - y_pred))\n","\n","# Loss for the full model, used for preparation and hidding networks\n","def full_loss(y_true, y_pred):\n","    # Loss for the full model is: |C-C'| + beta * |S-S'|\n","    s_true, c_true = y_true[:,:,:,0:3], y_true[:,:,:,3:6]\n","    s_pred, c_pred = y_pred[:,:,:,0:3], y_pred[:,:,:,3:6]\n","    s_loss = K.sum(K.square(s_true - s_pred))\n","    c_loss = K.sum(K.square(c_true - c_pred))\n","    return s_loss + c_loss\n","\n","\n","# Returns the encoder as a Keras model, composed by Preparation and Hiding Networks.\n","def make_encoder(input_size):\n","    input_S = Input(shape=(input_size))\n","    input_C= Input(shape=(input_size))\n","\n","    x = input_S\n","    \n","    # Preparation Network\n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_3x3')(x) #changed\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_4x4')(x) #changed\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_5x5')(x) #changed\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x = concatenate([input_C, x])\n","    \n","    # Hiding network\n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid5_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    output_Cprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_C')(x)\n","    \n","    return Model(inputs=[input_S, input_C], #changed\n","                 outputs=output_Cprime,\n","                 name = 'Encoder')\n","\n","# Returns the decoder as a Keras model, composed by the Reveal Network\n","def make_decoder(input_size, fixed=False):\n","    \n","    # Reveal network\n","    reveal_input = Input(shape=(input_size))\n","\n","    # Adding Gaussian noise with 0.01 standard deviation.\n","    x = GaussianNoise(0.01, name='output_C_noise')(reveal_input) #changed\n","  \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_3x3')(x) #changed\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_3x3')(x)\n","    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_4x4')(x)\n","    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev5_5x5')(x)\n","    x = concatenate([x3, x4, x5])\n","    \n","    output_Sprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_S')(x)\n","    \n","    if not fixed:\n","        return Model(inputs=reveal_input,\n","                     outputs=output_Sprime,\n","                     name = 'Decoder')\n","    # else:\n","    #     return Container(inputs=reveal_input,\n","    #                      outputs=output_Sprime,\n","    #                      name = 'DecoderFixed')                    # Changed\n","    else:\n","      return Network(inputs= reveal_input,   #changed\n","                      outputs=output_Sprime,\n","                      name = 'DecoderFixed')\n","\n","# Full model.\n","def make_model(input_size):\n","    input_S = Input(shape=(input_size))\n","    input_C= Input(shape=(input_size)) \n","    \n","    encoder = make_encoder(input_size)\n","    \n","    decoder = make_decoder(input_size)\n","    decoder.compile(optimizer='adam', loss=rev_loss)\n","    decoder.trainable = False\n","    \n","    output_Cprime = encoder([input_S, input_C]) #changed\n","    output_Sprime = decoder(output_Cprime) #changed\n","\n","    autoencoder = Model(inputs=[input_S, input_C],\n","                        outputs=concatenate([output_Sprime, output_Cprime]))\n","    autoencoder.compile(optimizer='adam', loss=full_loss)\n","    return encoder, decoder, autoencoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pet6hgLwe06S"},"source":["def Train(e) :\n","  NB_EPOCHS = e\n","  BATCH_SIZE = 32\n","  m = input_S.shape[0]\n","  ae_loss_history = []\n","  rev_loss_history = []\n","  encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])\n","  for epoch in range(NB_EPOCHS):\n","      np.random.shuffle(input_S)\n","      np.random.shuffle(input_C)\n","      \n","      t = tqdm(range(0, input_S.shape[0], BATCH_SIZE),mininterval=0)\n","      ae_loss = []\n","      rev_loss = []\n","      for idx in t:\n","          \n","          batch_S = input_S[idx:min(idx + BATCH_SIZE, m)]\n","          batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n","          \n","          C_prime = encoder_model.predict([batch_S, batch_C])\n","          \n","          ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S, batch_C], y=np.concatenate((batch_S, batch_C),axis=3)))\n","          rev_loss.append(reveal_model.train_on_batch(x=C_prime,y=batch_S))\n","          \n","          # Update learning rate\n","          K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n","          K.set_value(reveal_model.optimizer.lr, lr_schedule(epoch))\n","          \n","          t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss)))\n","      ae_loss_history.append(np.mean(ae_loss))\n","      rev_loss_history.append(np.mean(rev_loss))\n","  return ae_loss_history, rev_loss_history, encoder_model, reveal_model, autoencoder_model "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WAY6-Tv_e3xq"},"source":["ae_loss_history, rev_loss_history, encoder_model, reveal_model, autoencoder_model = Train(50)\n","autoencoder_model.save_weights('/content/drive/My Drive/Model/baluja_autoencoder_model_100k_10k_50e.hdf5')\n","encoder_model.save_weights('/content/drive/My Drive/Model/baluja_encoder_model_100k_10k_50e.hdf5')\n","reveal_model.save_weights('/content/drive/My Drive/Model/baluja_reveal_model_100k_10k_50e.hdf5')\n","plt.plot(ae_loss_history)\n","plt.title('Model loss')\n","plt.ylabel('ae_Loss')\n","plt.xlabel('1st 50 Epoch')\n","plt.show()\n","plt.plot(rev_loss_history)\n","plt.title('Model loss')\n","plt.ylabel('rev_Loss')\n","plt.xlabel('1st 50 Epoch')\n","plt.show()"],"execution_count":null,"outputs":[]}]}